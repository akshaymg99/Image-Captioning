{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Flatten,Input, Convolution2D, Dropout, LSTM, TimeDistributed, Embedding, Bidirectional, Activation, RepeatVector,Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(img_path):\n",
    "    im = image.load_img(img_path, target_size=(224,224,3))\n",
    "    im = image.img_to_array(im)\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    return im\n",
    "\n",
    "def get_encoding(model, img):\n",
    "    image = preprocessing(img)\n",
    "    pred = model.predict(image).reshape(2048)\n",
    "    return pred\n",
    "\n",
    "def predict_captions(image):\n",
    "    start_word = [\"<start>\"]\n",
    "    max_len = 40\n",
    "    while True:\n",
    "        par_caps = [word_2_indices[i] for i in start_word]\n",
    "        par_caps = sequence.pad_sequences([par_caps], maxlen=max_len, padding='post')\n",
    "        preds = model.predict([np.array([image]), np.array(par_caps)])\n",
    "        word_pred = indices_2_word[np.argmax(preds[0])]\n",
    "        start_word.append(word_pred)\n",
    "        if word_pred == \"<end>\" or len(start_word) > max_len:\n",
    "            break\n",
    "            \n",
    "    return ' '.join(start_word[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '../input/flickr8k/Images/'\n",
    "captions_path = '../input/flickr8k-text/flickr8k.token.txt'\n",
    "train_path = '../input/flickr8k-text/flickr_8k.trainImages.txt'\n",
    "val_path = '../input/flickr8k-text/flickr_8k.devImages.txt'\n",
    "test_path = '../input/flickr8k-text/flickr_8k.testImages.txt'\n",
    "\n",
    "captions = open(captions_path, 'r').read().split(\"\\n\")\n",
    "x_train = open(train_path, 'r').read().split(\"\\n\")\n",
    "x_val = open(val_path, 'r').read().split(\"\\n\")\n",
    "x_test = open(test_path, 'r').read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {}\n",
    "\n",
    "for ix in range(len(captions)-1):\n",
    "    temp = captions[ix].split(\"#\")\n",
    "    if temp[0] in tokens:\n",
    "        tokens[temp[0]].append(temp[1][2:])\n",
    "    else:\n",
    "        tokens[temp[0]] = [temp[1][2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = captions[10].split(\"#\")\n",
    "from IPython.display import Image, display\n",
    "z = Image(filename=images_path+temp[0])\n",
    "display(z)\n",
    "\n",
    "for ix in range(len(tokens[temp[0]])):\n",
    "    print(tokens[temp[0]][ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = open('../custom/flickr_8k_train_dataset.txt','wb')\n",
    "train_dataset.write(b\"image_id\\tcaptions\\n\")\n",
    "\n",
    "val_dataset = open('../custom/flickr_8k_val_dataset.txt','wb')\n",
    "val_dataset.write(b\"image_id\\tcaptions\\n\")\n",
    "\n",
    "test_dataset = open('../custom/flickr_8k_test_dataset.txt','wb')\n",
    "test_dataset.write(b\"image_id\\tcaptions\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in x_train:\n",
    "    if img == '':\n",
    "        continue\n",
    "    for capt in tokens[img]:\n",
    "        caption = \"<start> \"+ capt + \" <end>\"\n",
    "        train_dataset.write((img+\"\\t\"+caption+\"\\n\").encode())\n",
    "        train_dataset.flush()\n",
    "train_dataset.close()\n",
    "\n",
    "for img in x_val:\n",
    "    if img == '':\n",
    "        continue\n",
    "    for capt in tokens[img]:\n",
    "        caption = \"<start> \"+ capt + \" <end>\"\n",
    "        val_dataset.write((img+\"\\t\"+caption+\"\\n\").encode())\n",
    "        val_dataset.flush()\n",
    "val_dataset.close()\n",
    "\n",
    "for img in x_test:\n",
    "    if img == '':\n",
    "        continue\n",
    "    for capt in tokens[img]:\n",
    "        caption = \"<start> \"+ capt + \" <end>\"\n",
    "        test_dataset.write((img+\"\\t\"+caption+\"\\n\").encode())\n",
    "        test_dataset.flush()\n",
    "test_dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),pooling='avg')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {}\n",
    "ctr=0\n",
    "for ix in x_train:\n",
    "    if ix == \"\":\n",
    "        continue\n",
    "    if ctr >= 3000:\n",
    "        break\n",
    "    ctr+=1\n",
    "    if ctr%1000==0:\n",
    "        print(ctr)\n",
    "    path = images_path + ix\n",
    "    img = preprocessing(path)\n",
    "    pred = model.predict(img).reshape(2048)\n",
    "    train_data[ix] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( \"../custom/train_encoded_images.pkl\", \"wb\" ) as pickle_f:\n",
    "    pickle.dump(train_data, pickle_f )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_dataset = pd.read_csv(\"../custom/flickr_8k_train_dataset.txt\", delimiter='\\t')\n",
    "ds = pd_dataset.values\n",
    "\n",
    "sentences = []\n",
    "for ix in range(ds.shape[0]):\n",
    "    sentences.append(ds[ix, 1])\n",
    "print(len(sentences))\n",
    "\n",
    "words = [i.split() for i in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = []\n",
    "for i in words:\n",
    "    unique.extend(i)\n",
    "unique = list(set(unique))\n",
    "vocab_size = len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_2_indices = {val:index for index, val in enumerate(unique)}\n",
    "indices_2_word = {index:val for index, val in enumerate(unique)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_2_indices['UNK'] = 0\n",
    "word_2_indices['raining'] = 8253\n",
    "indices_2_word[0] = 'UNK'\n",
    "indices_2_word[8253] = 'raining'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in sentences:\n",
    "    i = i.split()\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences, subsequent_words = [], []\n",
    "for ix in range(ds.shape[0]):\n",
    "    partial_seqs = []\n",
    "    next_words = []\n",
    "    text = ds[ix, 1].split()\n",
    "    text = [word_2_indices[i] for i in text]\n",
    "    for i in range(1, len(text)):\n",
    "        partial_seqs.append(text[:i])\n",
    "        next_words.append(text[i])\n",
    "    padded_partial_seqs = sequence.pad_sequences(partial_seqs, max_len, padding='post')\n",
    "    next_words_1hot = np.zeros([len(next_words), vocab_size], dtype=np.bool)\n",
    "    for i,next_word in enumerate(next_words):\n",
    "        next_words_1hot[i, next_word] = 1\n",
    "    padded_sequences.append(padded_partial_seqs)\n",
    "    subsequent_words.append(next_words_1hot)\n",
    "    \n",
    "padded_sequences = np.asarray(padded_sequences)\n",
    "subsequent_words = np.asarray(subsequent_words)\n",
    "print(padded_sequences.shape)\n",
    "print(subsequent_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_images = 2000\n",
    "captions = np.zeros([0, max_len])\n",
    "next_words = np.zeros([0, vocab_size])\n",
    "for ix in range(num_of_images):#img_to_padded_seqs.shape[0]):\n",
    "    captions = np.concatenate([captions, padded_sequences[ix]])\n",
    "    next_words = np.concatenate([next_words, subsequent_words[ix]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../custom/train_encoded_images.pkl', 'rb') as f:\n",
    "    encoded_images = pickle.load(f, encoding=\"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for ix in range(ds.shape[0]):\n",
    "    if ds[ix, 0] in encoded_images.keys():\n",
    "        imgs.append(list(encoded_images[ds[ix, 0]]))\n",
    "imgs = np.asarray(imgs)\n",
    "print(imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "image_names = []\n",
    "\n",
    "for ix in range(num_of_images):\n",
    "    for iy in range(padded_sequences[ix].shape[0]):\n",
    "        images.append(imgs[ix])\n",
    "        \n",
    "images = np.asarray(images)\n",
    "np.save(\"../custom/images.npy\", images)\n",
    "print(images.shape)\n",
    "\n",
    "for ix in range(num_of_images):\n",
    "    for iy in range(padded_sequences[ix].shape[0]):\n",
    "        image_names.append(ds[ix, 0])\n",
    "        \n",
    "image_names = np.asarray(image_names)\n",
    "np.save(\"../custom/image_names.npy\", image_names)\n",
    "print(len(image_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(\"../custom/images.npy\")\n",
    "imag = np.load(\"../custom/image_names.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "max_len = 40\n",
    "\n",
    "image_model = Sequential()\n",
    "image_model.add(Dense(embedding_size, input_shape=(2048,), activation='relu'))\n",
    "image_model.add(RepeatVector(max_len))\n",
    "image_model.summary()\n",
    "\n",
    "language_model = Sequential()\n",
    "language_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_len))\n",
    "language_model.add(LSTM(256, return_sequences=True))\n",
    "language_model.add(TimeDistributed(Dense(embedding_size)))\n",
    "language_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conca = Concatenate()([image_model.output, language_model.output])\n",
    "x = LSTM(128, return_sequences=True)(conca)\n",
    "x = LSTM(512, return_sequences=False)(x)\n",
    "x = Dense(vocab_size)(x)\n",
    "out = Activation('softmax')(x)\n",
    "model = Model(inputs=[image_model.input, language_model.input], outputs = out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit([images, captions], next_words, batch_size=512, epochs=200)\n",
    "model.save_weights(\"../custom/model_weights.h5\")\n",
    "model.save(\"../custom/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = \"../input/flickr8k/Images/1000268201_693b08cb0e.jpg\"\n",
    "test_img = get_encoding(resnet, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = image.load_img(img)\n",
    "display(z)\n",
    "\n",
    "Argmax_Search = predict_captions(test_img)\n",
    "print(Argmax_Search)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
